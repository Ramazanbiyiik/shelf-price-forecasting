# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KISHtH3W9D0gIOULHTS3xBSLtk5V5epW
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import matplotlib.pyplot as plt
import joblib

# Load datasets
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

# Handle date column if exists
if 'date' in train_df.columns:
    train_df['date'] = pd.to_datetime(train_df['date'])
    train_df['month'] = train_df['date'].dt.month
    train_df['year'] = train_df['date'].dt.year
    train_df = train_df.drop('date', axis=1)

    if 'date' in test_df.columns:
        test_df['date'] = pd.to_datetime(test_df['date'])
        test_df['month'] = test_df['date'].dt.month
        test_df['year'] = test_df['date'].dt.year
        test_df = test_df.drop('date', axis=1)

# Fill missing values
for col in train_df.columns:
    if train_df[col].dtype == 'object':
        train_df[col] = train_df[col].fillna(train_df[col].mode()[0])
        if col in test_df.columns:
            test_df[col] = test_df[col].fillna(train_df[col].mode()[0])
    else:
        train_df[col] = train_df[col].fillna(train_df[col].median())
        if col in test_df.columns:
            test_df[col] = test_df[col].fillna(train_df[col].median())

# Define target and features
target = 'product_price'
y = train_df[target]
X = train_df.drop(target, axis=1)

# Separate categorical and numerical columns
categorical_cols = [col for col in X.columns if X[col].dtype == 'object']
numerical_cols = [col for col in X.columns if X[col].dtype != 'object']

# Train-validation split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ])

# Define models
models = {
    'RandomForest': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
    ]),
    'XGBoost': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=42))
    ]),
    'LightGBM': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', LGBMRegressor(n_estimators=100, learning_rate=0.05, random_state=42))
    ])
}

# Train and evaluate models
model_scores = {}
best_model = None
best_score = float('inf')

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    model_scores[name] = rmse

    if rmse < best_score:
        best_score = rmse
        best_model = model

# Plot model performance
plt.figure(figsize=(8, 5))
plt.bar(model_scores.keys(), model_scores.values())
plt.title('Model Performance Comparison (RMSE)')
plt.ylabel('RMSE (Lower is better)')
plt.show()

# Align test columns with train
missing_cols = set(X.columns) - set(test_df.columns)
for col in missing_cols:
    test_df[col] = 0

test_df = test_df[X.columns]

# Make predictions
test_predictions = best_model.predict(test_df)

# Submission file
submission_df = pd.DataFrame({
    'id': test_df['id'] if 'id' in test_df.columns else test_df.index,
    'product_price': test_predictions
})
submission_df.to_csv('submission.csv', index=False)

